<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Fridays with Faraday</title>
    <description>Working with microcontrollers, embedded systems, and performance optimization</description>
    <link>/</link>
    <language>en-us</language>
    <lastBuildDate>Sun, 02 Nov 2025 14:48:27 GMT</lastBuildDate>
    
    
    <item>
      <title><![CDATA[Minimal Bare Metal Bootloader]]></title>
      <description><![CDATA[**ARM Cortex-M4** • **Bootloader** • **Assembly**]]></description>
      <link>/experiments/bootloader.html</link>
      <guid>/experiments/bootloader.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Getting ESP32 to 12µA Sleep Current]]></title>
      <description><![CDATA[**Tags:** ESP32 • Low Power • Deep Sleep]]></description>
      <link>/experiments/esp32-low-power.html</link>
      <guid>/experiments/esp32-low-power.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[High-Speed ADC with DMA]]></title>
      <description><![CDATA[**STM32F4** **DMA** **ADC**]]></description>
      <link>/experiments/stm32-dma.html</link>
      <guid>/experiments/stm32-dma.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[ESP32 High-Speed ADC Performance: DMA and Interrupt Analysis]]></title>
      <description><![CDATA[High-speed analog-to-digital conversion on microcontrollers often becomes CPU-bound long before hitting the advertised sampling rates. The ESP32 integrates two successive approximation register (SAR) ]]></description>
      <link>/experiments/esp32-adc-performance.html</link>
      <guid>/experiments/esp32-adc-performance.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[ESP32 Power Management Trade-offs: Register-Level Investigation]]></title>
      <description><![CDATA[Power management on ESP32 involves complex trade-offs between voltage regulation efficiency, clock configuration optimization, power domain control, and application performance requirements. While Esp]]></description>
      <link>/experiments/esp32-power-management.html</link>
      <guid>/experiments/esp32-power-management.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Achieving Sub‑1µA Sleep Currents on ESP32: A Register‑Level, Memory‑ and Timing‑Aware Methodology]]></title>
      <description><![CDATA[Ultra‑low power systems demand a disciplined understanding of silicon behavior, memory placement, and clock/power domains. On the ESP32, sleep current is shaped by Dynamic Frequency Scaling (DFS), aut]]></description>
      <link>/experiments/esp32-ultra-low-power.html</link>
      <guid>/experiments/esp32-ultra-low-power.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[ESP32 Real-Time WiFi Performance: MAC Layer Analysis]]></title>
      <description><![CDATA[Achieving reliable real-time WiFi performance on ESP32 presents unique challenges due to the complex interactions between the IEEE 802.11 MAC layer, firmware drivers, and application timing constraint]]></description>
      <link>/experiments/esp32-wifi-performance.html</link>
      <guid>/experiments/esp32-wifi-performance.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Gaudi2 Memory Subsystem Analysis and Optimization: Deep Technical Guide]]></title>
      <description><![CDATA[In AI accelerator design, the memory subsystem determines whether theoretical compute performance translates into real-world performance. Gaudi2's memory architecture represents a radical departure fr]]></description>
      <link>/experiments/gaudi-memory-subsystem.html</link>
      <guid>/experiments/gaudi-memory-subsystem.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Mixed-Precision Arithmetic Performance on Gaudi2: FP16/BF16 Implementation Analysis]]></title>
      <description><![CDATA[Mixed-precision arithmetic represents one of the most significant advances in deep learning acceleration, reducing computational requirements and memory bandwidth while maintaining model accuracy. Gau]]></description>
      <link>/experiments/gaudi-mixed-precision.html</link>
      <guid>/experiments/gaudi-mixed-precision.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Gaudi2 vs NVIDIA H100: A Deep Technical Performance Analysis]]></title>
      <description><![CDATA[When Intel released the Gaudi2 accelerator, the market's immediate question was simple: how does it stack up against NVIDIA's H100? After extensive testing and analysis, the answer is nuanced but defi]]></description>
      <link>/experiments/gaudi-vs-h100.html</link>
      <guid>/experiments/gaudi-vs-h100.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Gaudi2 Architecture Deep Dive for AI Workloads]]></title>
      <description><![CDATA[Intel’s Gaudi2 is a second-generation AI training accelerator built around a deliberate separation of concerns: a configurable Matrix Multiplication Engine (MME) optimized for GEMMs and convolutions, ]]></description>
      <link>/experiments/gaudi2-architecture.html</link>
      <guid>/experiments/gaudi2-architecture.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[DirectX Video API Performance: Driver Internals Analysis]]></title>
      <description><![CDATA[Modern video decode pipelines push complex coordination requirements across user-mode APIs, driver layers, and GPU command submission paths. DirectX Video Acceleration 2.0 (DXVA2) formalized a clear s]]></description>
      <link>/experiments/dxva-performance.html</link>
      <guid>/experiments/dxva-performance.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[GPU Acceleration Pipeline Analysis with Level Zero]]></title>
      <description><![CDATA[Intel's Level Zero API represents the lowest-level interface between applications and Intel GPU hardware, providing direct access to compute and acceleration capabilities. This report provides an in-d]]></description>
      <link>/experiments/level-zero-analysis.html</link>
      <guid>/experiments/level-zero-analysis.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Multi-threading Performance with VAAPI]]></title>
      <description><![CDATA[Video processing workloads represent one of the most computationally demanding scenarios in modern graphics systems, requiring sophisticated multi-threading strategies to achieve optimal performance. ]]></description>
      <link>/experiments/vaapi-multithreading.html</link>
      <guid>/experiments/vaapi-multithreading.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Cache Hierarchy Optimization in Attention Mechanisms]]></title>
      <description><![CDATA[This deep technical analysis examines cache hierarchy optimization in attention mechanisms for transformer models, focusing on CPU cache behavior, memory access patterns, and cache miss analysis. Thro]]></description>
      <link>/experiments/llm-cache-hierarchy.html</link>
      <guid>/experiments/llm-cache-hierarchy.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[CPU vs GPU Inference: A System Call Analysis]]></title>
      <description><![CDATA[This deep technical analysis examines system-level behavior during CPU vs GPU inference for large language models, focusing on process scheduling, system calls, and hardware interrupt patterns. Throug]]></description>
      <link>/experiments/llm-cpu-gpu-system-calls.html</link>
      <guid>/experiments/llm-cpu-gpu-system-calls.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Tracing GPU Memory Bandwidth in Transformer Models]]></title>
      <description><![CDATA[Transformer inference at scale is dominated by memory traffic, not floating-point arithmetic. Across a broad set of modern models and batch sizes, decode-phase attention kernels exhibit arithmetic int]]></description>
      <link>/experiments/llm-gpu-memory-bandwidth.html</link>
      <guid>/experiments/llm-gpu-memory-bandwidth.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Hardware-Accelerated Matrix Multiplication Deep Dive]]></title>
      <description><![CDATA[This deep technical analysis examines hardware-accelerated matrix multiplication in CUDA kernels, providing a comprehensive reverse engineering study of CUDA kernels, PTX assembly analysis, and perfor]]></description>
      <link>/experiments/llm-matrix-multiplication.html</link>
      <guid>/experiments/llm-matrix-multiplication.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Memory Bandwidth Bottlenecks in Large Language Models]]></title>
      <description><![CDATA[This deep technical analysis examines memory bandwidth bottlenecks in large language model inference, using strace, perf, and advanced memory profiling techniques to identify and resolve performance l]]></description>
      <link>/experiments/llm-memory-bottlenecks.html</link>
      <guid>/experiments/llm-memory-bottlenecks.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
    
    <item>
      <title><![CDATA[Batch Processing Performance Analysis in vLLM]]></title>
      <description><![CDATA[Batch processing in vLLM represents the architectural foundation that enables high-throughput language model inference through dynamic batching, intelligent scheduling, and continuous memory managemen]]></description>
      <link>/experiments/vllm-batch-processing.html</link>
      <guid>/experiments/vllm-batch-processing.html</guid>
      <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
      <category><![CDATA[experiments]]></category>
    </item>
  
  </channel>
</rss>