---
title: "CUDA Kernel Fusion: Reducing Memory Traffic for Elementwise-Heavy Workloads"
author: "stanley-phoong"
description: "A performance-focused guide to kernel fusion for CUDA: when it pays off, how much memory traffic it saves, and the trade-offs in register pressure and occupancy for transformer-style elementwise ops."
publishDate: 2020-10-24
category: gpu-programming
tags: [cuda, kernel-fusion, memory-traffic, transformers, optimization, performance]
difficulty: advanced
readingTime: 19
---

import Callout from '@/components/mdx/Callout.astro';
import PerfChart from '@/components/mdx/PerfChart.astro';
import Benchmark from '@/components/mdx/Benchmark.astro';

In transformer inference, many kernels are short, bandwidth-heavy elementwise operations: bias add, activation, dropout, residual add, layernorm, etc. Launching each as a separate kernel:
- thrashes L2 and global memory
- burns launch overhead

Kernel fusion addresses this by **reading data once, doing more math, and writing once**.

## A simple example: bias + GELU + residual

Naive:

```cuda
__global__ void add_bias(float* x, const float* b, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i < n) x[i] += b[i];
}

__global__ void gelu(float* x, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i < n) {
    float v = x[i];
    x[i] = 0.5f * v * (1.0f + erff(v * 0.70710678f));
  }
}

__global__ void add_residual(float* x, const float* residual, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i < n) x[i] += residual[i];
}
```

Each kernel:
- reads x
- maybe reads another array
- writes x back

Total: **multiple round-trips** to DRAM per element.

Fused:

```cuda
__global__ void fused_bias_gelu_residual(
    float* x, const float* b, const float* residual, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i < n) {
    float v = x[i];
    v += b[i];                           // bias
    float g = 0.5f * v * (1.0f + erff(v * 0.70710678f)); // GELU
    v = g + residual[i];                // residual
    x[i] = v;                           // single write
  }
}
```

## Memory traffic comparison

Assume sizeof(float) = 4 bytes, arrays length N:

<Benchmark
  title="Approximate DRAM traffic per element"
  columns={["Pattern", "Reads", "Writes", "Total bytes"]}
  rows={[
    { values: ["Unfused (3 kernels)", "x:3 + b:1 + res:1", "x:3", " (3+1+1+3)·4 = 32 bytes"], highlight: false },
    { values: ["Fused", "x:1 + b:1 + res:1", "x:1", " (1+1+1+1)·4 = 16 bytes"], highlight: true },
  ]}
/>

Roughly **2× less DRAM traffic** for this toy pattern.

If the kernel is memory-bound, halving bytes can nearly double speed.

<PerfChart
  title="Speedup vs fusion (memory-bound case, example)"
  type="bar"
  data={{
    labels: ["Unfused", "Fused"],
    datasets: [{
      label: "Relative time",
      data: [1.0, 0.55],
      backgroundColor: ["#ef4444", "#10b981"],
    }]
  }}
/>

## Trade-offs: register pressure and occupancy

Fusion:
- increases live values per thread → more registers
- might reduce occupancy

If you go too far, you may:
- spill to local memory (negating benefits)
- under-occupy and fail to hide latency

<Callout type="warning" title="Don’t fuse blindly">
  Fusion helps when you’re **bandwidth-bound** and registers stay under control. If you’re already compute-bound or register-limited, more fusion can hurt.
</Callout>

## Transformer-style fusion targets

Good fusion candidates:
- bias + activation
- dropout + residual add
- layernorm + residual add (with care)
- multiple pointwise ops on the same tensor

Less ideal:
- ops with very different access patterns (e.g., matmul + softmax + dropout)
- anything that requires drastically different tiling

## Measuring impact

1. Measure baseline kernel times and memory BW
2. Fuse obvious elementwise sequences
3. Re-measure:
   - bytes moved (from profiler)
   - kernel time
   - register count/occupancy (from SASS or `nvcc --ptxas-options=-v`)

If bytes drop significantly and register count stays reasonable, you win.

## Conclusion

Kernel fusion is about **moving bytes, not just moving code**:
- fewer DRAM trips per element
- fewer kernel launches
- better cache reuse

Use it in transformer inference to collapse chains of elementwise ops, but always check the register and occupancy trade-offs in a profiler instead of guessing.

