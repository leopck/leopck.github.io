---
title: "ESP32 I2C Optimization: Throughput, Latency, and Real-World Signal Integrity"
author: "stanley-phoong"
description: "A performance deep-dive into ESP32 I2C: clocking, pull-ups, rise time, transaction packing, ISR vs polling, and how to measure bus utilization. Includes practical optimizations for high-rate sensors."
publishDate: 2020-05-20
category: microcontrollers
tags: [esp32, i2c, optimization, latency, throughput, embedded, sensors, performance]
difficulty: advanced
readingTime: 17
---

import Callout from '@/components/mdx/Callout.astro';
import PerfChart from '@/components/mdx/PerfChart.astro';
import Benchmark from '@/components/mdx/Benchmark.astro';

I2C “works” at 100 kHz with almost anything. But if you’re trying to pull IMU data at 1–4 kHz, stream multiple sensors, or keep the CPU asleep between bursts, I2C becomes a performance engineering problem: **bus utilization, transaction overhead, and signal integrity** all matter.

This post focuses on measurable optimizations on ESP32-class parts.

## Throughput model: payload vs overhead

An I2C read isn’t just “N bytes.” It’s:
- START
- 7-bit address + R/W + ACK
- register address write (often)
- repeated START
- address + ACK
- N data bytes + ACKs + NACK
- STOP

At 400 kHz, overhead can dominate small reads.

<Benchmark
  title="Transaction structure cost"
  columns={["Operation", "Bits on wire (approx)", "Notes"]}
  rows={[
    { values: ["Address phase", "~9", "7-bit addr + R/W + ACK"], highlight: false },
    { values: ["Register addr (8-bit)", "~9", "data + ACK"], highlight: false },
    { values: ["Repeated start + addr", "~9", "common for register reads"], highlight: true },
    { values: ["Each data byte", "~9", "8 data + ACK/NACK"], highlight: true },
  ]}
/>

## Signal integrity first: rise time sets your real max clock

If your SDA/SCL rise time is slow, 400 kHz can fail silently (retries, clock stretching, corrupted reads).

Rule-of-thumb:
\[
t_r \approx 0.8473 \cdot R_{pullup} \cdot C_{bus}
\]

Smaller pull-up → faster rise but higher idle current.

<Callout type="tip" title="Measure with a logic analyzer">
  Don’t guess. Measure SCL/SDA rise time and bus errors. Most “performance” regressions here are actually electrical.
</Callout>

## ESP32 configuration: 100k / 400k / 1MHz

ESP32 I2C supports higher clocks on some variants, but peripherals and wiring often cap you.

```cpp
#include "driver/i2c.h"

static void i2c_init(int port, int sda, int scl, uint32_t clk_hz) {
  i2c_config_t conf = {};
  conf.mode = I2C_MODE_MASTER;
  conf.sda_io_num = (gpio_num_t)sda;
  conf.scl_io_num = (gpio_num_t)scl;
  conf.sda_pullup_en = GPIO_PULLUP_ENABLE;
  conf.scl_pullup_en = GPIO_PULLUP_ENABLE;
  conf.master.clk_speed = clk_hz;

  i2c_param_config((i2c_port_t)port, &conf);
  i2c_driver_install((i2c_port_t)port, conf.mode, 0, 0, 0);
}
```

## Optimization 1: pack reads into bursts

Instead of reading 6 registers as 6 transactions, read a single burst:

```cpp
// Good: one burst read
read_regs(dev, start_reg, buf, 14); // accel+gyro+temp in one shot

// Bad: multiple small reads
read_reg(dev, REG_AXL, &axl);
read_reg(dev, REG_AXH, &axh);
// ...
```

Why it matters: address + repeated-start overhead is amortized.

<PerfChart
  title="Effective payload efficiency vs bytes per transaction"
  type="line"
  data={{
    labels: ["1", "2", "4", "8", "16", "32"],
    datasets: [{
      label: "Efficiency (payload / total)",
      data: [0.18, 0.29, 0.42, 0.55, 0.68, 0.78],
      borderColor: "#3b82f6",
    }]
  }}
/>

## Optimization 2: avoid “read-modify-read” patterns

Cache configuration registers in RAM and only write when changed. Re-reading config every loop burns bus time.

## Optimization 3: reduce per-call overhead (command link reuse)

ESP-IDF’s I2C driver uses command links; allocating/freeing them per transaction adds CPU overhead.

```cpp
// Pseudocode: reuse command link buffers for fixed transactions
i2c_cmd_handle_t cmd = i2c_cmd_link_create_static(buf, sizeof(buf));
// build fixed transaction once if possible, then execute
```

## Optimization 4: choose polling vs ISR wisely

For short bursts, polling can be cheaper than interrupt storms. For sustained streaming, DMA/FIFO-based peripherals beat CPU-driven I2C.

<Benchmark
  title="Polling vs interrupt trade-off"
  columns={["Mode", "Pros", "Cons"]}
  rows={[
    { values: ["Polling", "Low overhead for short bursts", "CPU busy-wait"], highlight: false },
    { values: ["ISR-driven", "CPU free between events", "IRQ overhead + jitter"], highlight: true },
  ]}
/>

## Optimization 5: schedule I2C around WiFi/BLE

On ESP32, WiFi/BLE activity can introduce latency jitter. If you need deterministic sensor timing:
- put I2C reads in a high-priority task
- pin to a core if you’re dual-core
- batch reads and timestamp on completion

## Measuring bus utilization

Define:
\[
U = \frac{\text{bits transferred}}{\text{clock\_rate} \cdot \text{time}}
\]

You can approximate in software by timing transactions and counting bytes:

```cpp
uint64_t t0 = esp_timer_get_time();
read_regs(dev, reg, buf, n);
uint64_t dt = esp_timer_get_time() - t0;

// bits: address+overhead ~ 27 bits + 9*n data bits (rough)
double bits = 27.0 + 9.0 * n;
double util = bits / (400000.0 * (dt / 1e6));
```

## Example results (illustrative)

<Benchmark
  title="I2C optimization impact (400 kHz bus)"
  columns={["Pattern", "Bytes", "Time (µs)", "Reads/s"]}
  rows={[
    { values: ["14× 1-byte reads", "14", "2100", "476"], highlight: false },
    { values: ["1× 14-byte burst", "14", "420", "2380"], highlight: true },
    { values: ["1× 32-byte burst", "32", "760", "1315"], highlight: true },
  ]}
/>

## Conclusion

I2C optimization is mostly about **reducing transactions** and **getting the electrical layer right**:
- Burst reads beat many small reads
- Signal integrity (pull-ups, capacitance) caps real speed
- Driver overhead matters at high rates
- Scheduling around WiFi/BLE reduces jitter

Once you treat I2C as a bandwidth budget, performance becomes predictable.

